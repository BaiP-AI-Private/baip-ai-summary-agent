# Daily AI Summary Agent ğŸ¤–ğŸ“°

This project delivers automated daily summaries of the latest breakthroughs, product launches, and strategic moves from top AI companies like OpenAI, Anthropic, xAI, Google DeepMind, and more.

Powered by a custom-built AI agent, the summaries are automatically generated by scraping company posts on X (Twitter) and using OpenAI GPT to distill the most important insights â€” all delivered to your Slack channel before you start your day.

## ğŸ“ Directory Structure

```
ai-summary-agent/
â”œâ”€â”€ .env                          # Environment variables (not in git)
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ tweet_scraper.log            # Application logs
â””â”€â”€ scripts/                     # All scripts and utilities
    â”œâ”€â”€ README.md                # Scripts documentation
    â”œâ”€â”€ tweet_scraper.py         # ğŸ¯ Main scraper script
    â”œâ”€â”€ ai_summary_agent.py      # Backup implementation
    â”œâ”€â”€ test_slack.py            # Slack integration test
    â”œâ”€â”€ test_openai.py           # OpenAI API test
    â””â”€â”€ test_full_functionality.py # Complete system test
```

## ğŸš€ Quick Start

### 1. Clone and Setup
```bash
git clone <repository-url>
cd ai-summary-agent
pip install -r requirements.txt
```

### 2. Configure Environment
```bash
cp .env.example .env
# Edit .env with your API keys (see setup sections below)
```

### 3. Run the Script
```bash
cd scripts
python tweet_scraper.py
```

## âš™ï¸ Configuration

### Required Environment Variables

Create a `.env` file in the root directory with:

```bash
OPENAI_API_KEY=your_openai_api_key_here
SLACK_WEBHOOK_URL=your_slack_webhook_url_here
```

## ğŸ”§ Setting Up OpenAI API

### 1. Create an OpenAI Account
- Go to [https://platform.openai.com/signup](https://platform.openai.com/signup) and create an account, or sign in if you already have one.

### 2. Generate an API Key
- Visit the [API keys page](https://platform.openai.com/api-keys).
- Click on **"Create new secret key"**.
- Copy the generated key. This is your `OPENAI_API_KEY`.

### 3. Add to Environment
Add the key to your `.env` file:
```bash
OPENAI_API_KEY=sk-proj-your-key-here
```

**âš ï¸ Important:** Keep your API key private. Never commit it to version control.

## ğŸ“± Setting Up Slack Webhook

### 1. Create a Slack Webhook
1. Go to your Slack workspace
2. Visit: https://api.slack.com/apps â†’ **Create New App**
3. Select **"From scratch"**
4. Add **Incoming Webhooks** under Features
5. **Activate Incoming Webhooks**
6. **Add new Webhook** to your workspace and select the target channel
7. Copy the Webhook URL (e.g., `https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX`)

### 2. Add to Environment
Add the webhook URL to your `.env` file:
```bash
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
```

## ğŸƒâ€â™‚ï¸ Usage

### Main Script
Run the daily AI summary scraper:
```bash
cd scripts
python tweet_scraper.py
```

### Testing Scripts
Test individual components:

```bash
cd scripts

# Test Slack integration
python test_slack.py

# Test OpenAI API
python test_openai.py

# Test complete functionality with mock data
python test_full_functionality.py
```

## ğŸ” How It Works

1. **ğŸ•·ï¸ Data Scraping**: Scrapes tweets from major AI companies using Nitter instances
2. **ğŸ¤– AI Processing**: Uses OpenAI GPT to analyze and summarize the content
3. **ğŸ“Š Smart Categorization**: Automatically categorizes updates by type (products, research, partnerships, etc.)
4. **ğŸ“¤ Slack Delivery**: Posts formatted summaries to your configured Slack channel
5. **ğŸ”„ Fallback System**: Multiple backup mechanisms ensure reliable operation

### Monitored Companies
- OpenAI
- xAI (Elon Musk's AI company)
- Anthropic
- Google DeepMind
- Mistral AI
- Meta AI
- Cohere
- Perplexity AI
- Scale AI
- Runway ML
- DAIR.AI

## ğŸ›¡ï¸ Reliability Features

### Multi-Layer Fallback System
1. **Primary**: AI-powered summary via OpenAI
2. **Secondary**: Manual categorized summary when AI is unavailable
3. **Tertiary**: Demo summary when no data is available

### Error Handling
- Graceful handling of service outages (Nitter, OpenAI)
- Comprehensive logging for debugging
- Error notifications sent to Slack
- Automatic retry mechanisms

### Robust Architecture
- Multiple Nitter instance support with automatic failover
- Rate limiting to respect service limits
- Timeout handling for network requests
- Unicode and encoding issue resolution

## ğŸ“‹ Dependencies

Install via `pip install -r requirements.txt`:

- `openai>=1.12.0` - OpenAI API client
- `requests>=2.31.0` - HTTP requests
- `python-dotenv>=1.0.1` - Environment variable management
- `beautifulsoup4>=4.12.3` - HTML parsing
- `pytz>=2024.1` - Timezone handling

## ğŸ”§ Troubleshooting

### Common Issues

**1. "No working sources found"**
- This is normal when Nitter instances are down
- The script will automatically use demo mode
- Check logs for more details

**2. "OpenAI quota exceeded"**
- The script will fall back to manual summarization
- Check your OpenAI billing and usage limits
- Consider upgrading your OpenAI plan

**3. "Slack webhook failed"**
- Verify your `SLACK_WEBHOOK_URL` is correct
- Check if the Slack app has proper permissions
- Test with `python test_slack.py`

### Logs
Check `tweet_scraper.log` for detailed execution logs and error information.

## ğŸš€ Deployment Options

### Manual Execution
Run the script manually when needed:
```bash
cd scripts && python tweet_scraper.py
```

### Scheduled Execution
Set up with cron (Linux/Mac) or Task Scheduler (Windows):

**Linux/Mac cron example (daily at 9 AM):**
```bash
0 9 * * * cd /path/to/ai-summary-agent/scripts && python tweet_scraper.py
```

**Windows Task Scheduler:**
- Create a new task
- Set trigger for daily execution
- Set action to run: `python C:\path\to\ai-summary-agent\scripts\tweet_scraper.py`

### GitHub Actions (CI/CD)
The project supports automated deployment via GitHub Actions with proper secrets configuration.

## ğŸ¤ Contributing

This project demonstrates the power of AI automation for staying ahead of fast-moving industry trends. 

**Have suggestions?**
- Additional AI companies to monitor
- New data sources or platforms
- Feature improvements
- Bug reports

Feel free to open issues or submit pull requests!

## ğŸ“ˆ Future Enhancements

- Support for additional social media platforms
- Integration with RSS feeds and company blogs
- Sentiment analysis and trend detection
- Multi-language support
- Web dashboard for managing sources and viewing analytics
- Integration with other communication platforms (Discord, Teams, etc.)

---

*This is just a glimpse of how we can use AI to automate research and stay ahead of fast-moving trends. Imagine the possibilities as we extend this approach across other domains!* ğŸš€
