name: Daily AI Summary

on:
  schedule:
    - cron: '0 11 * * *'  # 11:00 UTC daily
  workflow_dispatch:

jobs:
  generate-summary:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Install Playwright browsers
      run: |
        playwright install chromium
        playwright install-deps chromium

    - name: Set environment variables
      run: |
        echo "SSL_CERT_FILE=$(python -c 'import certifi; print(certifi.where())')" >> $GITHUB_ENV
        echo "REQUESTS_CA_BUNDLE=$SSL_CERT_FILE" >> $GITHUB_ENV

    - name: Test setup
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      run: cd scripts && python test_setup.py
      continue-on-error: true

    - name: Run AI summary generator
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      run: cd scripts && python twitter_scraper_new.py
    - name: Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: scraper-logs
        path: tweet_scraper.log
        retention-days: 7
